# 🔍 今日概览

**TODO**
- [x] `split_VR_Infer`代码优化
- [x] `hdf5_split`代码优化

---
# ⏱️ 时间轴日志（9:00 - 22:00）

|    **时间段**    |       **事项记录**       | **问题记录** |          **关键进展**           |
| :-----------: | :------------------: | :------- | :-------------------------: |
| 09:00 - 10:00 | `split_VR_Infer`代码优化 |          | 添加当日日期校正，批量处理文件夹名包含当日日期的文件夹 |
| 10:00 - 11:00 |   `hdf5_split`代码优化   |          |       直接在`NAS`上操作走不通        |
| 11:00 - 12:00 |   `hdf5_split`代码优化   |          |       尝试先缓存本地，处理之后再上传       |
| 12:00 - 13:00 |     🍽️ 午餐 / 休息      |          |                             |
| 13:00 - 14:00 |   `hdf5_split`代码优化   |          |           代码逻辑构思            |
| 14:00 - 15:00 |   `hdf5_split`代码优化   |          |    过滤已生成`HDF5`的`json`文件     |
| 15:00 - 16:00 |   `hdf5_split`代码优化   |          |             测试              |
| 16:00 - 17:00 |   `hdf5_split`代码优化   |          |             测试              |
| 17:00 - 18:00 |   `hdf5_split`代码优化   |          |             测试              |
| 18:00 - 19:00 |     🍽️ 晚餐 / 休息      |          |                             |
| 19:00 - 20:00 |                      |          |                             |
| 20:00 - 21:00 |                      |          |                             |
| 21:00 - 22:00 |                      |          |                             |

---
# 📥 今日充电

## `NAS`挂载命令

```bash
sudo apt install nfs-common
mkdir ~/na3-volume3
sudo mount -t nfs 10.156.56.222:/volume3/Nas_extend_data /home/midea/na3-volume3/

mkdir ~/na3-volume1
sudo mount -t nfs 10.156.56.222:/volume1/robot-data-nas3 /home/midea/na3-volume1/
```

## `hdf5_split`代码优化

**存在问题**
1. 在`NAS`上运行时，出现 ==导出失败：Can't decrement id ref count (unable to close file, errno = 5, error message = 'Input/output error')）==
==Segmentation fault (core dumped)== 错误。

**问题排查**
1. 将`HDF5`文件和`json`文件下载到本地，成功运行
2. 修改源代码，增加异常处理逻辑，减少线程数，添加重试机制，分块读取，仍出现同样错误

**问题原因**
1. `NAS` 存储的 `I/O 延迟`
2. `HDF5` 软件的 “句柄管理” 触发 “交接失败”


> [!question] `HDF5`文件加载到内存，还与`NAS`有关么
> 1. `HDF5` 默认是 "延迟加载"
> 2. 代码打开 `HDF5` 文件后，会生成一个 “**文件句柄**”，只有代码明确调用`h5py.File.close()`关闭句柄，绑定才会解除。
> 3. 写入新文件时，仍需和` NAS `交互

**解决方案**
1. 先把 NAS 上的原始 HDF5 文件完整复制到本地磁盘（如`/tmp`临时目录），在本地完成切分后，再把小文件上传回 NAS。这样能把 “与 NAS 的多次交互” 压缩为 “1 次下载 + 1 次上传”，从根源上避免中间过程的网络波动影响。
2. 延长 HDF5 和系统的超时阈值（适配 NAS 延迟）

**具体细节**
采用解决方案1，需要考虑特殊情况（如当天标注不完全），具体细节如下：
1. 检索`json`文件夹，如果不存在`json`文件夹或`json`文件则不进行处理
2. 列出`json`文件夹和`json`文件名
3. 检索目标文件夹，如果已经处理，则跳过该`HDF5`
4. 显示下载、处理、上传进度
5. 除了处理当天文件夹，还需处理任意日期文件夹
6. 需添加日志记录功能
7. 一边下载一边处理或者下载好了之后再处理

**解决结果**
1. 可正常在`NAS`上运行
2. 可通过日志快速定位问题

---
# 🧠 总结与反思

| 项目           | 内容                         |
|----------------|------------------------------|
| 🎯 是否达成目标 |                              |
| 🧱 碰到的困难   |                              |
| 🧰 解决方法     |                              |
| ✨ 明日优化点   |                              |
| 💭 自我感受     |                              |

---

# 📌 明日计划

- [ ] 
- [ ] 
- [ ] 
