---
tags:
  - work
date: 2025-11-24
location: SHANGHAI
---
# âœ… **ä»Šæ—¥å¾…åŠžäº‹é¡¹ï¼ˆTop 3ï¼‰**  
- [ ] ðŸŽ¯ 1.  
- [ ] ðŸ”§ 2.  
- [ ] ðŸ“š 3.  


---
# ðŸ•’ **æ—¶é—´è½´æ—¥å¿—ï¼ˆ07:00 - 23:00ï¼‰**

|      æ—¶é—´æ®µ      |   ðŸ“Œ äº‹é¡¹è®°å½•   | â— é—®é¢˜è®°å½• | ðŸ§© åŽŸå› åˆ†æž | ðŸ› ï¸ è§£å†³æ–¹æ¡ˆ | ðŸš€ å…³é”®è¿›å±• |
| :-----------: | :---------: | :----: | :-----: | :------: | :-----: |
| 08:00 - 09:00 |  ðŸ“‹ è§„åˆ’å…¨å¤©äº‹é¡¹  |        |         |          |         |
| 09:00 - 10:00 |             |        |         |          |         |
| 10:00 - 11:00 |             |        |         |          |         |
| 11:00 - 12:00 |             |        |         |          |         |
| 12:00 - 13:00 | ðŸ½ï¸ åˆé¤ / ä¼‘æ¯ |        |         |          |         |
| 13:00 - 14:00 |             |        |         |          |         |
| 14:00 - 15:00 |             |        |         |          |         |
| 15:00 - 16:00 |             |        |         |          |         |
| 16:00 - 17:00 |             |        |         |          |         |
| 17:00 - 18:00 |             |        |         |          |         |
| 18:00 - 19:00 | ðŸ½ï¸ æ™šé¤ / ä¼‘æ¯ |        |         |          |         |
| 19:00 - 20:00 |             |        |         |          |         |
| 20:00 - 21:00 |             |        |         |          |         |
| 21:00 - 22:00 |   ðŸ“ ä»Šæ—¥æ€»ç»“   |        |         |          |         |


---
# ðŸ’¼ **å·¥ä½œè®°å½•**

> è®°å½•ä»Šæ—¥å…·ä½“å·¥ä½œå†…å®¹ã€PRã€Bug ä¿®å¤ã€ä¼šè®®çºªè¦ã€å…³é”®å†³ç­–ç­‰ã€‚

- ðŸ“Œ å·¥ä½œå†…å®¹ä¸€ï¼š
- ðŸ“Œ å·¥ä½œå†…å®¹äºŒï¼š
- ðŸ“Œ é‡è¦è®¨è®ºï¼š



---
# ðŸ”‹ **ä»Šæ—¥å……ç”µ / å­¦ä¹ **

> é˜…è¯»æ–‡ç« ã€è¯¾ç¨‹ã€è§†é¢‘ã€æŠ€æœ¯æ–‡æ¡£ã€åšå®¢æ‘˜è¦ç­‰

## LLaMA-Factory

**ä»‹ç»**
LLaMA Factory is an easy-to-use and efficient platform for training and fine-tuning large language models. With LLaMA Factory, you can fine-tune hundreds of pre-trained models locally without writing any code. Framework features include:
- Models: LLaMA, LLaVA, Mistral, Mixtral-MoE, Qwen, Yi, Gemma, Baichuan, ChatGLM, Phi, etc.
- Trainers: (incremental) pre-training, (multimodal) instruction supervision fine-tuning, reward model training, PPO training, DPO training, KTO training, ORPO training, etc.
- Computation Precision: 16-bit full-parameter fine-tuning, frozen fine-tuning, LoRA fine-tuning, and 2/3/4/5/6/8-bit QLoRA fine-tuning based on AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ.
- Optimization Algorithms: GaLore, BAdam, DoRA, LongLoRA, LLaMA Pro, Mixture-of-Depths, LoRA+, LoftQ, and PiSSA.
- Acceleration Operators: FlashAttention-2 and Unsloth.
- Inference Engines: Transformers and vLLM.
- Experiment Monitors: LlamaBoard, TensorBoard, Wandb, MLflow, SwanLab etc.

**éƒ¨ç½²**
```bash
# Install from Source
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
cd LLaMA-Factory
pip install -e ".[torch,metrics]"

# Install from Docker Image
docker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest
```

**è®­ç»ƒ**
```bash
llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml \
    learning_rate=1e-5 \
    logging_steps=1
```


**LLMæ–¹å‘**
- **LLMå¼€å‘**ï¼š**é¢„è®­ç»ƒ**ã€**å¾®è°ƒ**ã€**å¯¹é½** 
- **LLMåº”ç”¨**ï¼š**Agentå¼€å‘**ã€**RAG**ã€**å¤šæ¨¡æ€**
- **LLMå·¥ç¨‹åŒ–**ï¼š**æŽ¨ç†ä¼˜åŒ–**ã€**éƒ¨ç½²**ã€**æœåŠ¡åŒ–**


**Reference**
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
- [llamafactory Doc](https://llamafactory.readthedocs.io/en/latest/)
- [åŸºäºŽ Docker çš„ LLaMA-Factory å…¨æµç¨‹éƒ¨ç½²æŒ‡å—](https://zhuanlan.zhihu.com/p/1941515527517368861)
## VLAC

**Reference**
- [VLAC](https://github.com/InternRobotics/VLAC)


## AIè¾…åŠ©é˜…è¯»è®ºæ–‡

```plaintext
Summarize this PDF document in a bullet point outline.
Summarize this PDF document and create a PowerPoint presentation for sharing with the audience.
Can you continue to generate content for additional slides ï¼Ÿ
```


**Reference**
- [å¦‚ä½•ä½¿ç”¨AIé«˜æ•ˆè¯»è®ºæ–‡ï¼Œç…§åšè¿™äº›æ–¹æ³•å’ŒæŒ‡ä»¤ä½ ä¹Ÿå¯ä»¥ä¸€å¤©é˜…è¯»50ç¯‡](https://blog.csdn.net/wyj20082004/article/details/145269903)
- [ç ”ç©¶ç”Ÿä»¬åˆšå¼€å§‹çœ‹è‹±æ–‡æ–‡çŒ®æ˜¯æ€Žä¹ˆçœ‹çš„ï¼Ÿï¼ˆå…¨å¥—AIè¾…åŠ©é˜…è¯»æ”»ç•¥ï¼‰](https://www.zhihu.com/tardis/zm/art/712935413)



## è®ºæ–‡é˜…è¯»

**A Survey of Imitation Learning: Algorithms, Recent Developments, and Challenges**

learning from an expertâ€™s behavior through imitation is often more appealing. This is where imitation learning (IL) comes into play - a process where desired behavior is learned by imitating an expertâ€™s behavior,which is provided through **demonstrations**.

BC is an IL technique that treats the problem of learning a behavior as a supervised learning task. BC involves training a model to mimic an expertâ€™s behavior by learning to map the state of the environment to the corresponding expert action. The expertâ€™s behavior is recorded as a set of **state-action pairs**, also known as **demonstrations**. During the training process, the model is provided with these demonstrations as inputs and is trained to learn a function that maps the current state to the corresponding expert action. Once the model is trained, it can use the learned function to generate actions for new states that it has not encountered before.

One advantage of BC is that it requires no knowledge of the underlying dynamics of the environment . Instead,it relies solely on the provided demonstrations to learn the behavior. Additionally, BC is computationally efficient since it involves training a supervised learning model, which is a well-studied problem in machine learning.

Despite its simplicity, the BC approach has a significant drawback **- the covariate shift problem**.
This problem arises because during training, the learner is trained on states generated by the expert policy, but during testing, the learner is tested on states induced by its action . As a result, the state distribution observed during testing can differ from that observed during training. The problem with BC supervised approach is that the agent does not know how to return to the demonstrated states when it drifts and encounters out-of-distribution states. Covariate shift is particularly dangerous in safety-critical situations such as driving, as the agent may encounter novel situations that it has not seen during training, and its ability to recover from mistakes can be critical to avoid accidents. 

![[Pasted image 20251124140235.png]]

---
# ðŸ§  **æ€»ç»“ä¸Žåæ€**

| é¡¹ç›®         | å†…å®¹          |
| ---------- | ----------- |
| ðŸŽ¯ æ˜¯å¦è¾¾æˆç›®æ ‡  | âœ… / âŒï¼ˆç®€è¦è¯´æ˜Žï¼‰ |
| ðŸ§± ä»Šæ—¥é‡åˆ°çš„å›°éš¾ | ...         |
| ðŸ§° è§£å†³æ–¹æ³•    | ...         |
| âœ¨ æ˜Žæ—¥ä¼˜åŒ–ç‚¹    | ...         |
| ðŸ’­ ä»Šæ—¥æ„Ÿå—    | ...         |

---
# ðŸ“Œ **æ˜Žæ—¥è®¡åˆ’**

- [ ] âœ… å·¥ä½œç›®æ ‡ 1  
- [ ] ðŸ§ª å­¦ä¹  / å®žéªŒ 2  
- [ ] ðŸ“¬ è·Ÿè¿›äº‹é¡¹ 3  



---
# ðŸ“· å°ç»“å›¾åƒ / çµæ„Ÿï¼ˆå¯é€‰ï¼‰

> å¯æ’å…¥æˆªå›¾ã€è‰å›¾ã€è„‘å›¾æˆ–çµæ„Ÿç‚¹å­ç­‰  
> `![æˆªå›¾](assets/daily-2025-11-24.png)`





---
# ðŸ“Ž å¤‡æ³¨  
> è‡ªå®šä¹‰æ ‡ç­¾: `#daily #log #2025-11-24`
