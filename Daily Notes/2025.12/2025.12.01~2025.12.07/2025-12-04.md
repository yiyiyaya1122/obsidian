
[1] Model-Free Imitation Learning with Policy Optimization, OpenAI, 2016
[2] Generative Adversarial Imitation Learning, OpenAI, 2016
[3] One-Shot Imitation Learning, OpenAI, 2017
[4] Third-Person Imitation Learning, OpenAI, 2017
[5] Learning human behaviors from motion capture by adversarial imitation, DeepMind, 2017
[6] Robust Imitation of Diverse Behaviors, DeepMind, 2017
[7] Unsupervised Perceptual Rewards for Imitation Learning, Google Brain, 2017
[8] Time-Contrastive Networks: Self-Supervised Learning from Multi-View Observation, Google Brain, 2017
[9] Imitation from Observation/ Learning to Imitate Behaviors from Raw Video via Context Translation, OpenAI, 2017
[10] One Shot Visual Imitation Learning , OpenAI, 2017

![[Pasted image 20251204155928.png]]

**==强化学习分类==**

**基于模型的 vs 无模型的**
- **基于模型（Model-based）**：学习环境的动态模型，然后规划最优策略
- **无模型（Model-free）**：直接通过经验学习价值函数和策略

**价值方法 vs 策略方法 vs Actor-Critic**
- **价值方法（Value-based）**：学习价值函数，从中推导出策略，代表算法：Q-Learning，DQN     
- **策略方法（Policy-based）**：直接学习策略函数，代表算法：REINFORCE，PPO
- **Actor-Critic方法**：结合价值函数和策略函数，Actor负责选择动作，Critic评估动作价值

**按学习方式分类**
- **在线学习（On-policy）**：使用当前策略生成的数据来更新策略，代表算法：SARSA        
- **离线学习（Off-policy）**：可以使用其他策略生成的数据来更新当前策略，代表算法：Q-Learning



**Reference**
- [具身智能社区知识库](https://yv6uc1awtjc.feishu.cn/wiki/WPTzw9ON0ivIVrkLjVocNZh8nLf)
- [Embodied-AI-Guide](https://github.com/tianxingchen/Embodied-AI-Guide)

- [强化学习入门这一篇就够了！！！万字长文](https://blog.csdn.net/CltCj/article/details/119445005)
- [Policy-based Reinforcement learning](https://cltcj.blog.csdn.net/article/details/119815324?spm=1001.2014.3001.5502)
- [Value-Based Reinforcement Learning-DQN](https://cltcj.blog.csdn.net/article/details/119618632?spm=1001.2014.3001.5502)
- [Key Concepts in RL](https://spinningup.openai.com/en/latest/spinningup/rl_intro.html#id2)

