任务：环境配置
完成情况：绿盾、opevpn、Nvidia显卡驱动、CUDA、cuDNN、TensorRT



# 一、Nidia显卡驱动(apt install)

1. 禁用自带驱动
```bash
sudo gedit /etc/modprobe.d/blacklist_nouveau.conf

blacklist nouveau
options nouveau modeset=0
```

2. 卸载显卡驱动
```bash
sudo apt-get --purge remove nvidia-*
```

3. 查看系统中驱动版本，选择推荐的驱动版本进行安装：如安装535版本驱动命令如下
```bash
ubuntu-drivers devices
sudo apt install nvidia-driver-535
```

4. 重启电脑
```bash
reboot
```

5. 验证
```bash
nvidia-smi
```

6. 存在问题
``` bash
# 更新驱动之后重启电脑显示PPM init failed(-110)
# 采用独显直连

# 更新驱动前调节亮度没有反映  
# 更新Nidia显卡驱动之后可调节亮度
```
# 二、CUDA(`run`文件安装)

1. 下载cuda安装包：[CUDA安装包](https://developer.nvidia.com/cuda-toolkit-archive)
2. 安装：`sodo sh cuda_xxxxx.run`
3. 选择不安装驱动
![[Pasted image 20250320211322.png]]
![[Pasted image 20250320212224.png]]

4. 设置环境变量
```bash
export CUDA_HOME=/usr/local/cuda-10.2
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:${CUDA_HOME}/lib64
export PATH=${CUDA_HOME}/bin:${PATH}
```
5. 验证
```bash
# 查看版本信息
nvcc -V

# 编译测试
cd /usr/local/cuda-10.2/samples/1_Utilities/deviceQuery
make
./deviceQuery

```

# 三、CUDNN


1. 下载CUDNN安装包：[CUDNN安装包](https://developer.nvidia.com/rdp/cudnn-archive)
2. 解压
```bash
tar -xvf cudnn-linux-x86_64-8.x.x.x.tar.xz
```
3. 安装
```bash
sudo cp include/* /usr/local/cuda/include/
sudo cp lib64/* /usr/local/cuda/lib64/
sudo chmod a+r /usr/local/cuda/include/cudnn*.h usr/local/cuda/lib64/libcudnn*
```
4. 验证
```bash
cat /usr/local/cuda/include/cudnn.h | grep cudnn
```

# 四、TensorRT

参考资料
- [官方文档](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar)
- [参考1](https://zhuanlan.zhihu.com/p/392143346)
- [参考2](https://blog.51cto.com/u_12870633/6149817)
- [参考3](https://blog.csdn.net/u010420283/article/details/134634995?spm=1001.2014.3001.5506)

1. 下载TensorRT安装包：[TensorRT安装包](https://developer.nvidia.com/tensorrt/download)
2. 解压
```bash
version="8.x.x.x"
arch=$(uname -m)
cuda="cuda-x.x"
tar -xzvf TensorRT-${version}.Linux.${arch}-gnu.${cuda}.tar.gz
```
3. 移动到指定文件夹
```bash
mv TensorRT-${version} /usr/local
```
3. 添加环境变量
```bash
sudo gedit ~/.bashrc
```

```plaintext
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/TensorRT-${version}/lib
export C_INCLUDE_PATH=$C_INCLUDE_PATH:/usr/local/TensorRT-${version}/include

export CPLUS_INCLUDE_PATH=$CPLUS_INCLUDE_PATH:/usr/local/TensorRT-${version}/include
```

```bash
source ~/.bashrc
```

4. 验证
```bash
cd /usr/local/TensorRT-${version}/samples/sampleOnnxMNIST
sudo make
/usr/local/TensorRT-${version}/bin/sample_onnx_mnist
```
5. 验证报错
```bash
sudo rmmod nvidia_uvm
sudo modprobe nvidia_uvm
```

